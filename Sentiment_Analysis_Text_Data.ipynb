{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94aef98",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73bea912",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=21b988509bd5571563e9752ed84310b5188d722a5c62577d3b8103a058f09e45\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0899529",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hp\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e224864",
   "metadata": {},
   "source": [
    "# Scrapping for one website (Heading and Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e46c1c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headings:\n",
      "AI in healthcare to Improve Patient Outcomes\n",
      "\n",
      "Paragraphs:\n",
      "Ranking customer behaviours for business strategy\n",
      "Algorithmic trading for multiple commodities markets, like Forex, Metals, Energy, etc.\n",
      "Trading Bot for FOREX\n",
      "Python model for the analysis of sector-specific stock ETFs for investment purposes\n",
      "AutoGPT Setup\n",
      "Playstore & Appstore to Google Analytics (GA) or Firebase to Google Data Studio Mobile App KPI Dashboard\n",
      "Google Local Service Ads LSA API To Google BigQuery to Google Data Studio\n",
      "AI Conversational Bot using RASA\n",
      "Rise of telemedicine and its Impact on Livelihood by 2040\n",
      "Rise of e-health and its impact on humans by the year 2030\n",
      "Rise of e-health and its impact on humans by the year 2030\n",
      "Rise of telemedicine and its Impact on Livelihood by 2040\n",
      "AI/ML and Predictive Modeling\n",
      "Solution for Contact Centre Problems\n",
      "How to Setup Custom Domain for Google App Engine Application?\n",
      "Code Review Checklist\n",
      "Introduction\n",
      "“If anything kills over 10 million people in the next few decades, it will be a highly infectious virus rather than a war. Not missiles but microbes.” Bill Gates’s remarks at a TED conference in 2014, right after the world had avoided the Ebola outbreak. When the new, unprecedented, invisible virus hit us, it met an overwhelmed and unprepared healthcare system and oblivious population. This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities. For the past few years, artificial intelligence has proven to be of tangible potential in the healthcare sectors, clinical practices, translational medical and biomedical research.\n",
      "After the first case was detected in China on December 31st 2019, it was an AI program developed by BlueDot that alerted the world about the pandemic. It was quick to realise AI’s ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus.\n",
      "Many tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of cross-infection by using AI algorithms that can track patterns and extract some features to classify or categorise them.\n",
      "So how does AI do that?\n",
      "IBM Watson, a sophisticated AI that works on cloud computing and natural language processing, has prominently contributed to the healthcare sector on a global level. Being a conversational AI, since 2013, Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs.\n",
      "Researchers at Google Inc. showed that an AI system can be trained on thousands of images to achieve physician-level sensitivity.\n",
      "By identifying the molecular patterns associated with disease status and its subtypes, gene expression, and protein abundance levels, machine learning methods can detect fatal diseases like cancer at an early stage. Machine Learning (ML) techniques focus mainly on analyzing structured data, which can further help in clustering patients’ traits and infer the probability of disease outcomes. Since patient traits mainly include masses of data relating to age, gender, disease history, disease-specific data like diagnostic imaging and gene expressions, etc, ML can extract features from these data inputs by constructing data analytical algorithms.\n",
      "ML algorithms are either supervised or unsupervised. Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases. Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters. Since patient traits are recorded in multiple dimensions, such as genes, principal component analysis(PCA) creates the apparatus to reduce these dimensions which humans could have not done alone.\n",
      "Supervised learning considers the outcomes of the subjects together with the traits, and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event, expected value of a disease level or expected survival time, or risk of Down’s syndrome.\n",
      "Biomarker panels that are mostly used to detect ovarian cancer, have outperformed the conventional statistical methods due to machine learning. In addition to this, the use of EHRs and Bayesian networks, which are a part of supervised machine learning algorithms, can predict clinical outcomes and mortality respectively.\n",
      "Unstructured data such as clinical notes and texts are converted into machine-readable structured data with the help of natural language processing(NLP). NLP works with two components: text processing and classification. Text processing helps in identifying a series of disease-relevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases. Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients. Healthcare organizations use NLP-based chatbots to increase interactions with patients, keeping their mental health and wellness in check.\n",
      "Deep learning is a modern extension of the classical neural network techniques which helps explore more complex non-linear patterns in data, using algorithms like convolution neural network, recurrent neural network, deep belief network, and deep neural network which enables more accurate clinical prediction. When it comes to genome interpretation, deep neural networks surpass the conventional methods of logistics regression and support vector machines.\n",
      "Sepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patient’s risk score and identify the early stages of sepsis.\n",
      "Another method known as the Learning-based Optimization of the Under Sampling Pattern( LOUPE) is based on integrating full resolution MRI scans with the convolutional neural network algorithm, which helps in creating more accurate reconstructions.\n",
      "Robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery. Even after striking the right balance between human decisions and AI precision, robotic surgery reduces surgeon efficiency as they have to be manually operated through a console. Thus, autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs, cut tissues, etc., or robotic catheters that can navigate whether it is touching blood, tissue, or valve.\n",
      "Researchers at Children’s National Hospital, Washington have already developed an AI called Smart Tissue Autonomous Robot (STAR), which performs a colon anastomosis on its own with the help of an ML-powered suturing tool, that automatically detects the patient’s breathing pattern to apply suture at the correct point.\n",
      "Cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs. Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information, medications, and therapies.\n",
      "How can It help in Biomedical research?\n",
      "Since AI can analyze literature beyond readability, it can be used to concise biomedical research. With the help of ML algorithms and NLP, AI can accelerate screening and indexing of biomedical research, by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly. Taking it to the next level, AI systems like the computational modelling assistant (CMA) helps researchers to construct simulation models from the concepts they have in mind. Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and protein-protein interaction information extraction.\n",
      "AI as precision medicine\n",
      "Since precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile, the various AI devices pave the way to practice it more efficiently. With the help of ML, complex algorithms like large datasets can be used to predict and create an optimal treatment strategy.\n",
      "Deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patient’s emotional state, food intake, or health monitoring.\n",
      "“Omics” refers to the collective technologies that help in exploring the roles, relationships of various branches ending with the suffix “omics” such as genomics, proteomics, etc. Omics-based tests based on machine learning algorithms help find correlations and predict treatment responses, ultimately creating personalized treatments for individual patients.\n",
      "How it helps in psychology and neuro patients\n",
      "For psychologists studying creativity,  AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon. Studies show that  AI can conduct therapy sessions, e-therapy sessions, and assessments autonomously, also assisting human practitioners before, during, or after sessions. The Detection and Computational Analysis of Psychological Signal project uses ML, computer vision, and NLP to analyze language, physical gestures, and social signals to identify cues for human distress. This ground-breaking technology assesses soldiers returning from combat and recognizes those who require further mental health support. In the future, it will combine data captured during face-to-face interviews with information on sleeping, eating, and online behaviours for a complete patient view.\n",
      "Stroke identification\n",
      "Stroke is another frequently occurring disease that affects more than 500 million people worldwide. Thrombus,  in the vessel cerebral infarction is the major (about 85%) cause of stroke occurrence. In recent years, AI techniques have been used in numerous stroke-related studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem. With AI at our disposal, large amounts of data with rich information, more complications and real-life clinical questions can be addressed in this arena. Currently, two ML algorithms- genetic fuzzy finite state machine and PCA were implemented to build a model building solution. These include a human activity recognition stage and a stroke onset detection stage. An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded. ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis.\n",
      "Patient Monitoring\n",
      "Today, the market for AI-based patient monitoring is impressive and monetarily enticing. It is evolving with artificial sensors, smart technologies and explores everything from brain-computer interfaces to nanorobotics. Companies with their smart-watches have engaged people to perform remote monitoring even when they are not “patients”. An obvious place to start is with wearable and embedded sensors, glucose monitors, pulse monitors, oximeters, and ECG monitors. With patient monitoring becoming crucial, AI finds numerous applications in chronic conditions, intensive care units, operating rooms, emergency rooms, and cardiac wards where timeless clinical decision-making can be measured in seconds. More advances have started to gain traction like smart prosthetics and implants. These play an impeccable role in patient management post-surgery or rehabilitation. Demographics, laboratory results and vital signs can also be used to predict cardiac arrest, transfer into the intensive care unit, or even death. In addition, an interpretable machine-learning model can assist anesthesiologists in predicting hypoxaemia events during surgery. This suggests that with deep-learning algorithms, raw patient-monitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decision-making.\n",
      "Conclusion\n",
      "Considering the vast range of tasks that an AI can do, it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels. Using sophisticated algorithms AI can bring a revolution in the healthcare sector. Even after facing challenges like whether the technology will be able to deliver the promises, ethical measures, training physicians to use it, standard regulations etc, the role of AI in transforming the clinical practices cannot be ignored. The biggest challenge is the integration of AI in daily practice. All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective.\n",
      "We provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.\n",
      "Contact us: hello@blackcoffer.com\n",
      "© All Right Reserved, Blackcoffer(OPC) Pvt. Ltd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_website(url):\n",
    "    # Send a GET request to the website\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all heading tags (h1 ) and extract their text\n",
    "    headings = soup.find_all(['h1'])\n",
    "    heading_texts = [heading.text.strip() for heading in headings]\n",
    "\n",
    "    # Find all paragraph tags and extract their text\n",
    "    paragraphs = soup.find_all('p')\n",
    "    paragraph_texts = [paragraph.text.strip() for paragraph in paragraphs]\n",
    "\n",
    "    return heading_texts, paragraph_texts\n",
    "\n",
    "\n",
    "url = 'https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/'  \n",
    "headings, paragraphs = scrape_website(url)\n",
    "\n",
    "# Print the scraped headings\n",
    "print(\"Headings:\")\n",
    "for heading in headings:\n",
    "    print(heading)\n",
    "\n",
    "print()\n",
    "\n",
    "# Print the scraped paragraphs\n",
    "print(\"Paragraphs:\")\n",
    "for paragraph in paragraphs:\n",
    "    print(paragraph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d22652",
   "metadata": {},
   "source": [
    "# Removing the common & unnecessary sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35ca7667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headings:\n",
      "AI in healthcare to Improve Patient Outcomes\n",
      "\n",
      "Paragraphs:\n",
      "Introduction\n",
      "“If anything kills over 10 million people in the next few decades, it will be a highly infectious virus rather than a war. Not missiles but microbes.” Bill Gates’s remarks at a TED conference in 2014, right after the world had avoided the Ebola outbreak. When the new, unprecedented, invisible virus hit us, it met an overwhelmed and unprepared healthcare system and oblivious population. This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities. For the past few years, artificial intelligence has proven to be of tangible potential in the healthcare sectors, clinical practices, translational medical and biomedical research.\n",
      "After the first case was detected in China on December 31st 2019, it was an AI program developed by BlueDot that alerted the world about the pandemic. It was quick to realise AI’s ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus.\n",
      "Many tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of cross-infection by using AI algorithms that can track patterns and extract some features to classify or categorise them.\n",
      "So how does AI do that?\n",
      "IBM Watson, a sophisticated AI that works on cloud computing and natural language processing, has prominently contributed to the healthcare sector on a global level. Being a conversational AI, since 2013, Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs.\n",
      "Researchers at Google Inc. showed that an AI system can be trained on thousands of images to achieve physician-level sensitivity.\n",
      "By identifying the molecular patterns associated with disease status and its subtypes, gene expression, and protein abundance levels, machine learning methods can detect fatal diseases like cancer at an early stage. Machine Learning (ML) techniques focus mainly on analyzing structured data, which can further help in clustering patients’ traits and infer the probability of disease outcomes. Since patient traits mainly include masses of data relating to age, gender, disease history, disease-specific data like diagnostic imaging and gene expressions, etc, ML can extract features from these data inputs by constructing data analytical algorithms.\n",
      "ML algorithms are either supervised or unsupervised. Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases. Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters. Since patient traits are recorded in multiple dimensions, such as genes, principal component analysis(PCA) creates the apparatus to reduce these dimensions which humans could have not done alone.\n",
      "Supervised learning considers the outcomes of the subjects together with the traits, and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event, expected value of a disease level or expected survival time, or risk of Down’s syndrome.\n",
      "Biomarker panels that are mostly used to detect ovarian cancer, have outperformed the conventional statistical methods due to machine learning. In addition to this, the use of EHRs and Bayesian networks, which are a part of supervised machine learning algorithms, can predict clinical outcomes and mortality respectively.\n",
      "Unstructured data such as clinical notes and texts are converted into machine-readable structured data with the help of natural language processing(NLP). NLP works with two components: text processing and classification. Text processing helps in identifying a series of disease-relevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases. Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients. Healthcare organizations use NLP-based chatbots to increase interactions with patients, keeping their mental health and wellness in check.\n",
      "Deep learning is a modern extension of the classical neural network techniques which helps explore more complex non-linear patterns in data, using algorithms like convolution neural network, recurrent neural network, deep belief network, and deep neural network which enables more accurate clinical prediction. When it comes to genome interpretation, deep neural networks surpass the conventional methods of logistics regression and support vector machines.\n",
      "Sepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patient’s risk score and identify the early stages of sepsis.\n",
      "Another method known as the Learning-based Optimization of the Under Sampling Pattern( LOUPE) is based on integrating full resolution MRI scans with the convolutional neural network algorithm, which helps in creating more accurate reconstructions.\n",
      "Robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery. Even after striking the right balance between human decisions and AI precision, robotic surgery reduces surgeon efficiency as they have to be manually operated through a console. Thus, autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs, cut tissues, etc., or robotic catheters that can navigate whether it is touching blood, tissue, or valve.\n",
      "Researchers at Children’s National Hospital, Washington have already developed an AI called Smart Tissue Autonomous Robot (STAR), which performs a colon anastomosis on its own with the help of an ML-powered suturing tool, that automatically detects the patient’s breathing pattern to apply suture at the correct point.\n",
      "Cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs. Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information, medications, and therapies.\n",
      "How can It help in Biomedical research?\n",
      "Since AI can analyze literature beyond readability, it can be used to concise biomedical research. With the help of ML algorithms and NLP, AI can accelerate screening and indexing of biomedical research, by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly. Taking it to the next level, AI systems like the computational modelling assistant (CMA) helps researchers to construct simulation models from the concepts they have in mind. Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and protein-protein interaction information extraction.\n",
      "AI as precision medicine\n",
      "Since precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile, the various AI devices pave the way to practice it more efficiently. With the help of ML, complex algorithms like large datasets can be used to predict and create an optimal treatment strategy.\n",
      "Deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patient’s emotional state, food intake, or health monitoring.\n",
      "“Omics” refers to the collective technologies that help in exploring the roles, relationships of various branches ending with the suffix “omics” such as genomics, proteomics, etc. Omics-based tests based on machine learning algorithms help find correlations and predict treatment responses, ultimately creating personalized treatments for individual patients.\n",
      "How it helps in psychology and neuro patients\n",
      "For psychologists studying creativity,  AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon. Studies show that  AI can conduct therapy sessions, e-therapy sessions, and assessments autonomously, also assisting human practitioners before, during, or after sessions. The Detection and Computational Analysis of Psychological Signal project uses ML, computer vision, and NLP to analyze language, physical gestures, and social signals to identify cues for human distress. This ground-breaking technology assesses soldiers returning from combat and recognizes those who require further mental health support. In the future, it will combine data captured during face-to-face interviews with information on sleeping, eating, and online behaviours for a complete patient view.\n",
      "Stroke identification\n",
      "Stroke is another frequently occurring disease that affects more than 500 million people worldwide. Thrombus,  in the vessel cerebral infarction is the major (about 85%) cause of stroke occurrence. In recent years, AI techniques have been used in numerous stroke-related studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem. With AI at our disposal, large amounts of data with rich information, more complications and real-life clinical questions can be addressed in this arena. Currently, two ML algorithms- genetic fuzzy finite state machine and PCA were implemented to build a model building solution. These include a human activity recognition stage and a stroke onset detection stage. An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded. ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis.\n",
      "Patient Monitoring\n",
      "Today, the market for AI-based patient monitoring is impressive and monetarily enticing. It is evolving with artificial sensors, smart technologies and explores everything from brain-computer interfaces to nanorobotics. Companies with their smart-watches have engaged people to perform remote monitoring even when they are not “patients”. An obvious place to start is with wearable and embedded sensors, glucose monitors, pulse monitors, oximeters, and ECG monitors. With patient monitoring becoming crucial, AI finds numerous applications in chronic conditions, intensive care units, operating rooms, emergency rooms, and cardiac wards where timeless clinical decision-making can be measured in seconds. More advances have started to gain traction like smart prosthetics and implants. These play an impeccable role in patient management post-surgery or rehabilitation. Demographics, laboratory results and vital signs can also be used to predict cardiac arrest, transfer into the intensive care unit, or even death. In addition, an interpretable machine-learning model can assist anesthesiologists in predicting hypoxaemia events during surgery. This suggests that with deep-learning algorithms, raw patient-monitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decision-making.\n",
      "Conclusion\n",
      "Considering the vast range of tasks that an AI can do, it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels. Using sophisticated algorithms AI can bring a revolution in the healthcare sector. Even after facing challenges like whether the technology will be able to deliver the promises, ethical measures, training physicians to use it, standard regulations etc, the role of AI in transforming the clinical practices cannot be ignored. The biggest challenge is the integration of AI in daily practice. All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective.\n",
      "We provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.\n",
      "Contact us: hello@blackcoffer.com\n",
      "© All Right Reserved, Blackcoffer(OPC) Pvt. Ltd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_website(url):\n",
    "    # Send a GET request to the website\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all heading tags (h1 ) and extract their text\n",
    "    headings = soup.find_all(['h1'])\n",
    "    heading_texts = [heading.text.strip() for heading in headings]\n",
    "\n",
    "    # Find all paragraph tags and extract their text\n",
    "    paragraphs = soup.find_all('p')\n",
    "    paragraph_texts = [paragraph.text.strip() for paragraph in paragraphs]\n",
    "    \n",
    "    # Remove uunnecessary sentences\n",
    "    sentences_to_exclude = [\n",
    "        \"Ranking customer behaviours for business strategy\",\n",
    "        \"Algorithmic trading for multiple commodities markets, like Forex, Metals, Energy, etc.\",\n",
    "        \"Trading Bot for FOREX\",\n",
    "        \"Python model for the analysis of sector-specific stock ETFs for investment purposes\",\n",
    "        \"AutoGPT Setup\",\n",
    "        \"Playstore & Appstore to Google Analytics (GA) or Firebase to Google Data Studio Mobile App KPI Dashboard\",\n",
    "        \"Google Local Service Ads LSA API To Google BigQuery to Google Data Studio\",\n",
    "        \"AI Conversational Bot using RASA\",\n",
    "        \"Rise of telemedicine and its Impact on Livelihood by 2040\",\n",
    "        \"Rise of e-health and its impact on humans by the year 2030\",\n",
    "        \"Rise of telemedicine and its Impact on Livelihood by 2040\",\n",
    "        \"AI/ML and Predictive Modeling\",\n",
    "        \"Solution for Contact Centre Problems\",\n",
    "        \"How to Setup Custom Domain for Google App Engine Application?\",\n",
    "        \"Code Review Checklist\"\n",
    "    ]\n",
    "\n",
    "    cleaned_heading_texts = [heading for heading in heading_texts if heading not in sentences_to_exclude]\n",
    "    cleaned_paragraph_texts = [paragraph for paragraph in paragraph_texts if paragraph not in sentences_to_exclude]\n",
    "\n",
    "    return cleaned_heading_texts, cleaned_paragraph_texts\n",
    "    \n",
    "    return heading_texts, paragraph_texts\n",
    "\n",
    "\n",
    "url = 'https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/'  \n",
    "headings, paragraphs = scrape_website(url)\n",
    "\n",
    "# Print the scraped headings\n",
    "print(\"Headings:\")\n",
    "for heading in headings:\n",
    "    print(heading)\n",
    "\n",
    "print()\n",
    "\n",
    "# Print the scraped paragraphs\n",
    "print(\"Paragraphs:\")\n",
    "for paragraph in paragraphs:\n",
    "    print(paragraph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d3c198",
   "metadata": {},
   "source": [
    "# Doing the same for the whole dataset using for- loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a8123c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved content for URL_ID 37.0.\n",
      "Saved content for URL_ID 38.0.\n",
      "Saved content for URL_ID 39.0.\n",
      "Saved content for URL_ID 40.0.\n",
      "Saved content for URL_ID 41.0.\n",
      "Saved content for URL_ID 42.0.\n",
      "Saved content for URL_ID 43.0.\n",
      "Saved content for URL_ID 44.0.\n",
      "Saved content for URL_ID 45.0.\n",
      "Saved content for URL_ID 46.0.\n",
      "Saved content for URL_ID 47.0.\n",
      "Saved content for URL_ID 48.0.\n",
      "Saved content for URL_ID 49.0.\n",
      "Saved content for URL_ID 50.0.\n",
      "Saved content for URL_ID 51.0.\n",
      "Saved content for URL_ID 52.0.\n",
      "Saved content for URL_ID 53.0.\n",
      "Saved content for URL_ID 54.0.\n",
      "Saved content for URL_ID 55.0.\n",
      "Saved content for URL_ID 56.0.\n",
      "Saved content for URL_ID 57.0.\n",
      "Saved content for URL_ID 58.0.\n",
      "Saved content for URL_ID 59.0.\n",
      "Saved content for URL_ID 60.0.\n",
      "Saved content for URL_ID 61.0.\n",
      "Saved content for URL_ID 62.0.\n",
      "Saved content for URL_ID 63.0.\n",
      "Saved content for URL_ID 64.0.\n",
      "Saved content for URL_ID 65.0.\n",
      "Saved content for URL_ID 66.0.\n",
      "Saved content for URL_ID 67.0.\n",
      "Saved content for URL_ID 68.0.\n",
      "Saved content for URL_ID 69.0.\n",
      "Saved content for URL_ID 70.0.\n",
      "Saved content for URL_ID 71.0.\n",
      "Saved content for URL_ID 72.0.\n",
      "Saved content for URL_ID 73.0.\n",
      "Saved content for URL_ID 74.0.\n",
      "Saved content for URL_ID 75.0.\n",
      "Saved content for URL_ID 76.0.\n",
      "Saved content for URL_ID 77.0.\n",
      "Saved content for URL_ID 78.0.\n",
      "Saved content for URL_ID 79.0.\n",
      "Saved content for URL_ID 80.0.\n",
      "Saved content for URL_ID 81.0.\n",
      "Saved content for URL_ID 82.0.\n",
      "Saved content for URL_ID 83.0.\n",
      "Saved content for URL_ID 84.0.\n",
      "Saved content for URL_ID 85.0.\n",
      "Saved content for URL_ID 86.0.\n",
      "Saved content for URL_ID 87.0.\n",
      "Saved content for URL_ID 88.0.\n",
      "Saved content for URL_ID 89.0.\n",
      "Saved content for URL_ID 90.0.\n",
      "Saved content for URL_ID 91.0.\n",
      "Saved content for URL_ID 92.0.\n",
      "Saved content for URL_ID 93.0.\n",
      "Saved content for URL_ID 94.0.\n",
      "Saved content for URL_ID 95.0.\n",
      "Saved content for URL_ID 96.0.\n",
      "Saved content for URL_ID 97.0.\n",
      "Saved content for URL_ID 98.0.\n",
      "Saved content for URL_ID 99.0.\n",
      "Saved content for URL_ID 100.0.\n",
      "Saved content for URL_ID 101.0.\n",
      "Saved content for URL_ID 102.0.\n",
      "Saved content for URL_ID 103.0.\n",
      "Saved content for URL_ID 104.0.\n",
      "Saved content for URL_ID 105.0.\n",
      "Saved content for URL_ID 106.0.\n",
      "Saved content for URL_ID 107.0.\n",
      "Saved content for URL_ID 108.0.\n",
      "Saved content for URL_ID 109.0.\n",
      "Saved content for URL_ID 110.0.\n",
      "Saved content for URL_ID 111.0.\n",
      "Saved content for URL_ID 112.0.\n",
      "Saved content for URL_ID 113.0.\n",
      "Saved content for URL_ID 114.0.\n",
      "Saved content for URL_ID 115.0.\n",
      "Saved content for URL_ID 116.0.\n",
      "Saved content for URL_ID 117.0.\n",
      "Saved content for URL_ID 118.0.\n",
      "Saved content for URL_ID 119.0.\n",
      "Saved content for URL_ID 120.0.\n",
      "Saved content for URL_ID 121.0.\n",
      "Saved content for URL_ID 122.0.\n",
      "Saved content for URL_ID 123.0.\n",
      "Saved content for URL_ID 124.0.\n",
      "Saved content for URL_ID 125.0.\n",
      "Saved content for URL_ID 126.0.\n",
      "Saved content for URL_ID 127.0.\n",
      "Saved content for URL_ID 128.0.\n",
      "Saved content for URL_ID 129.0.\n",
      "Saved content for URL_ID 130.0.\n",
      "Saved content for URL_ID 131.0.\n",
      "Saved content for URL_ID 132.0.\n",
      "Saved content for URL_ID 133.0.\n",
      "Saved content for URL_ID 134.0.\n",
      "Saved content for URL_ID 135.0.\n",
      "Saved content for URL_ID 136.0.\n",
      "Saved content for URL_ID 137.0.\n",
      "Saved content for URL_ID 138.0.\n",
      "Saved content for URL_ID 139.0.\n",
      "Saved content for URL_ID 140.0.\n",
      "Saved content for URL_ID 141.0.\n",
      "Saved content for URL_ID 142.0.\n",
      "Saved content for URL_ID 143.0.\n",
      "Saved content for URL_ID 144.0.\n",
      "Saved content for URL_ID 145.0.\n",
      "Saved content for URL_ID 146.0.\n",
      "Saved content for URL_ID 147.0.\n",
      "Saved content for URL_ID 148.0.\n",
      "Saved content for URL_ID 149.0.\n",
      "Saved content for URL_ID 150.0.\n",
      "Scraping and saving complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_website(url):\n",
    "    # Send a GET request to the website\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Remove header and footer elements\n",
    "    headers = soup.find_all(['header', 'footer'])\n",
    "    for header in headers:\n",
    "        header.decompose()\n",
    "\n",
    "    # Remove elements with ID 'sidebar'\n",
    "    sidebar = soup.find(id='sidebar')\n",
    "    if sidebar:\n",
    "        sidebar.decompose()\n",
    "\n",
    "    # Remove elements with class 'tdm-descr'\n",
    "    descr_elements = soup.find_all(class_='tdm-descr')\n",
    "    for descr_element in descr_elements:\n",
    "        descr_element.decompose()\n",
    "\n",
    "    # Find all heading tags (h1) and extract their text\n",
    "    headings = soup.find_all(['h1'])\n",
    "    heading_texts = [heading.text.strip() for heading in headings]\n",
    "\n",
    "    # Find all paragraph tags and extract their text\n",
    "    paragraphs = soup.find_all('p')\n",
    "    paragraph_texts = [paragraph.text.strip() for paragraph in paragraphs]\n",
    "\n",
    "    # Remove specific sentences\n",
    "    sentences_to_exclude = [\n",
    "        \"Ranking customer behaviours for business strategy\",\n",
    "        \"Algorithmic trading for multiple commodities markets, like Forex, Metals, Energy, etc.\",\n",
    "        \"Trading Bot for FOREX\",\n",
    "        \"Python model for the analysis of sector-specific stock ETFs for investment purposes\",\n",
    "        \"AutoGPT Setup\",\n",
    "        \"Playstore & Appstore to Google Analytics (GA) or Firebase to Google Data Studio Mobile App KPI Dashboard\",\n",
    "        \"Google Local Service Ads LSA API To Google BigQuery to Google Data Studio\",\n",
    "        \"AI Conversational Bot using RASA\",\n",
    "        \"Rise of telemedicine and its Impact on Livelihood by 2040\",\n",
    "        \"Rise of e-health and its impact on humans by the year 2030\",\n",
    "        \"Rise of telemedicine and its Impact on Livelihood by 2040\",\n",
    "        \"AI/ML and Predictive Modeling\",\n",
    "        \"Solution for Contact Centre Problems\",\n",
    "        \"How to Setup Custom Domain for Google App Engine Application?\",\n",
    "        \"Code Review Checklist\"\n",
    "    ]\n",
    "\n",
    "    cleaned_heading_texts = [heading for heading in heading_texts if heading not in sentences_to_exclude]\n",
    "    cleaned_paragraph_texts = [paragraph for paragraph in paragraph_texts if paragraph not in sentences_to_exclude]\n",
    "\n",
    "    return cleaned_heading_texts, cleaned_paragraph_texts\n",
    "\n",
    "# Create a new folder for text files\n",
    "folder_name = 'Extracted_TextFiles'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Load the URLs from the Excel file\n",
    "df = pd.read_excel('input.xlsx')  # Replace with the path to your Excel file\n",
    "urls = df['URL']\n",
    "\n",
    "# Scrape and save content for each URL\n",
    "for index, url in enumerate(urls):\n",
    "    url_id = df['URL_ID'][index]\n",
    "    headings, paragraphs = scrape_website(url)\n",
    "\n",
    "    # Create a text file path\n",
    "    file_name = f\"{url_id}.txt\"\n",
    "    file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "    # Save the scraped content in the text file\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"Headings:\\n\")\n",
    "        for heading in headings:\n",
    "            file.write(heading + \"\\n\")\n",
    "        \n",
    "        file.write(\"\\nParagraphs:\\n\")\n",
    "        for paragraph in paragraphs:\n",
    "            file.write(paragraph + \"\\n\")\n",
    "\n",
    "    print(f\"Saved content for URL_ID {url_id}.\")\n",
    "\n",
    "print(\"Scraping and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747e73a",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81c5d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopword removal completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the folders\n",
    "extracted_text_folder = \"Extracted_TextFiles\"\n",
    "stopwords_folder = \"StopWords\"\n",
    "output_folder = \"Extracted_TextFiles_Stopword_removed\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "# Function to remove stopwords from a text file\n",
    "def remove_stopwords(text, stopwords_files):\n",
    "    stopwords = set()\n",
    "    for stopwords_file in stopwords_files:\n",
    "        with open(stopwords_file, 'r', encoding='latin-1') as file:\n",
    "            stopwords.update(set(file.read().splitlines()))\n",
    "\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_text\n",
    "\n",
    "# Process each text file\n",
    "for file_name in os.listdir(extracted_text_folder):\n",
    "    file_path = os.path.join(extracted_text_folder, file_name)\n",
    "    output_file_path = os.path.join(output_folder, file_name)\n",
    "    stopwords_files = [os.path.join(stopwords_folder, stopwords_file) for stopwords_file in os.listdir(stopwords_folder)]\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            filtered_text = remove_stopwords(text, stopwords_files)\n",
    "\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(filtered_text)\n",
    "\n",
    "print(\"Stopword removal completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af233f",
   "metadata": {},
   "source": [
    "# Analysing the POSITIVE and NEGATIVE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17744ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12716\\2261518555.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df = output_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  URL_ID                                                URL POSITIVE SCORE  \\\n",
       "0   37.0  https://insights.blackcoffer.com/ai-in-healthc...             55   \n",
       "1   38.0  https://insights.blackcoffer.com/what-if-the-c...             45   \n",
       "2   39.0  https://insights.blackcoffer.com/what-jobs-wil...             57   \n",
       "3   40.0  https://insights.blackcoffer.com/will-machine-...             39   \n",
       "4   41.0  https://insights.blackcoffer.com/will-ai-repla...             42   \n",
       "\n",
       "  NEGATIVE SCORE  \n",
       "0             26  \n",
       "1             28  \n",
       "2             29  \n",
       "3             14  \n",
       "4             18  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the input data from 'input.xlsx'\n",
    "input_df = pd.read_excel('input.xlsx')\n",
    "\n",
    "# Create a new DataFrame for the output data structure\n",
    "output_df = pd.DataFrame(columns=['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE'])\n",
    "\n",
    "# Read the positive words from 'positive-words.txt'\n",
    "positive_words = set()\n",
    "with open('positive-words.txt', 'r') as positive_file:\n",
    "    positive_words = set(positive_file.read().splitlines())\n",
    "\n",
    "    \n",
    "# Read the negative words from 'negetive-words.txt'\n",
    "negative_words = set()\n",
    "with open('negative-words.txt', 'r') as negative_file:\n",
    "    negative_words = set(negative_file.read().splitlines())\n",
    "    \n",
    "\n",
    "# Iterate over the URLs and text files\n",
    "for index, row in input_df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    file_name = f\"{url_id}.txt\"\n",
    "    file_path = os.path.join('Extracted_TextFiles_Stopword_removed', file_name)\n",
    "\n",
    "    # Read the text file\n",
    "    with open(file_path, 'r', encoding='utf-8') as text_file:\n",
    "        text_data = text_file.read()\n",
    "\n",
    "    # Calculate positive word count\n",
    "    wordcount_positive = sum(word in positive_words for word in text_data.split())\n",
    "    \n",
    "     # Calculate negative word count\n",
    "    wordcount_negative = sum(word in negative_words for word in text_data.split())\n",
    "\n",
    "    # Add the row to the output DataFrame\n",
    "    output_df = output_df.append({\n",
    "        'URL_ID': url_id,\n",
    "        'URL': url,\n",
    "        'POSITIVE SCORE': wordcount_positive,\n",
    "        'NEGATIVE SCORE': wordcount_negative,\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Save the output data to 'Output Data Structure.xlsx'\n",
    "output_df.to_excel('Output Data Structure.xlsx', index=False)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfea0dc",
   "metadata": {},
   "source": [
    "# Calculating the POLARITY SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34edf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  \n",
       "0              26        0.358025  \n",
       "1              28        0.232877  \n",
       "2              29        0.325581  \n",
       "3              14        0.471698  \n",
       "4              18        0.400000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the output data from 'Output Data Structure.xlsx'\n",
    "df = pd.read_excel('Output Data Structure.xlsx')\n",
    "\n",
    "# Calculate the polarity score for each row\n",
    "df['POLARITY SCORE'] = (df['POSITIVE SCORE'] - df['NEGATIVE SCORE']) / (df['POSITIVE SCORE'] + df['NEGATIVE SCORE'] + 0.000001)\n",
    "\n",
    "# Adjust the polarity score range to -1 to +1\n",
    "df['POLARITY SCORE'] = df['POLARITY SCORE'].clip(lower=-1, upper=1)\n",
    "\n",
    "# Save the updated data to 'Output Data Structure.xlsx'\n",
    "df.to_excel('Output Data Structure.xlsx', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a8204",
   "metadata": {},
   "source": [
    "# Calculating the SUBJECTIVITY SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50cec945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.069767</td>\n",
       "      <td>0.092275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.062925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.099010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.087838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.123552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \n",
       "0                55              26        0.358025            0.077885  \n",
       "1                45              28        0.232877            0.110774  \n",
       "2                57              29        0.325581            0.097175  \n",
       "3                39              14        0.471698            0.072503  \n",
       "4                42              18        0.400000            0.070671  \n",
       "..              ...             ...             ...                 ...  \n",
       "109              20              23       -0.069767            0.092275  \n",
       "110              29               8        0.567568            0.062925  \n",
       "111              25              35       -0.166667            0.099010  \n",
       "112              24               2        0.846154            0.087838  \n",
       "113              29              35       -0.093750            0.123552  \n",
       "\n",
       "[114 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over the rows in the output dataframe\n",
    "for index, row in output_df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    file_name = f\"{url_id}.txt\"\n",
    "    file_path = os.path.join('Extracted_TextFiles_Stopword_removed', file_name)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        # Read the text file and calculate the total words\n",
    "        with open(file_path, 'r', encoding='utf-8') as text_file:\n",
    "            text_data = text_file.read()\n",
    "            total_words = len(text_data.split())\n",
    "\n",
    "        # Calculate the subjectivity score using the formula\n",
    "        positive_score = row['POSITIVE SCORE']\n",
    "        negative_score = row['NEGATIVE SCORE']\n",
    "        subjectivity_score = (positive_score + negative_score) / (total_words + 0.000001)\n",
    "\n",
    "        # Adjust the subjectivity score range to 0 to +1\n",
    "        subjectivity_score = max(0, min(1, subjectivity_score))\n",
    "\n",
    "        # Update the SUBJECTIVITY SCORE column in the output dataframe\n",
    "        df.loc[index, 'SUBJECTIVITY SCORE'] = subjectivity_score\n",
    "\n",
    "# Save the updated data to 'Output Data Structure.xlsx'\n",
    "df.to_excel('Output Data Structure.xlsx', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa794a5",
   "metadata": {},
   "source": [
    "# Calculating the AVG SENTENCE LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "427a0576",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas nltk openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11117690",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE AVG SENTENCE LENGTH  \n",
       "0              26        0.358025            0.077885           16.786667  \n",
       "1              28        0.232877            0.110774           11.384615  \n",
       "2              29        0.325581            0.097175           13.107143  \n",
       "3              14        0.471698            0.072503            9.956044  \n",
       "4              18        0.400000            0.070671               14.25  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')  \n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)  \n",
    "df['AVG SENTENCE LENGTH'] = None  # Create a new column\n",
    "\n",
    "def calculate_avg_sentence_length(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    words = word_tokenize(text)\n",
    "    num_words = len(words)\n",
    "    if num_sentences > 0:\n",
    "        avg_length = num_words / num_sentences\n",
    "    else:\n",
    "        avg_length = 0\n",
    "    return avg_length\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            avg_sentence_length = calculate_avg_sentence_length(text)\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'AVG SENTENCE LENGTH'] = avg_sentence_length\n",
    "\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1307271",
   "metadata": {},
   "source": [
    "# Calculating the PERCENTAGE OF COMPLEX WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c06fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>52.660842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>35.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>52.22525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>39.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>41.643583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              26        0.358025            0.077885            16.786667   \n",
       "1              28        0.232877            0.110774            11.384615   \n",
       "2              29        0.325581            0.097175            13.107143   \n",
       "3              14        0.471698            0.072503             9.956044   \n",
       "4              18        0.400000            0.070671            14.250000   \n",
       "\n",
       "  PERCENTAGE OF COMPLEX WORDS  \n",
       "0                   52.660842  \n",
       "1                   35.810811  \n",
       "2                    52.22525  \n",
       "3                   39.735099  \n",
       "4                   41.643583  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)  \n",
    "df['PERCENTAGE OF COMPLEX WORDS'] = None  # Create a new column\n",
    "\n",
    "def calculate_percentage_complex_words(text):\n",
    "    words = word_tokenize(text)\n",
    "    num_complex_words = sum(1 for word in words if len(word) > 6)\n",
    "    num_words = len(words)\n",
    "    if num_words > 0:\n",
    "        percentage_complex_words = (num_complex_words / num_words) * 100\n",
    "    else:\n",
    "        percentage_complex_words = 0\n",
    "    return percentage_complex_words\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            percentage_complex_words = calculate_percentage_complex_words(text)\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'PERCENTAGE OF COMPLEX WORDS'] = percentage_complex_words\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df4e1a",
   "metadata": {},
   "source": [
    "# Calculating the FOG INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f18084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>52.660842</td>\n",
       "      <td>27.779003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>35.810811</td>\n",
       "      <td>18.87817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>52.225250</td>\n",
       "      <td>26.132957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>39.735099</td>\n",
       "      <td>19.876457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>41.643583</td>\n",
       "      <td>22.357433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              26        0.358025            0.077885            16.786667   \n",
       "1              28        0.232877            0.110774            11.384615   \n",
       "2              29        0.325581            0.097175            13.107143   \n",
       "3              14        0.471698            0.072503             9.956044   \n",
       "4              18        0.400000            0.070671            14.250000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \n",
       "0                    52.660842  27.779003  \n",
       "1                    35.810811   18.87817  \n",
       "2                    52.225250  26.132957  \n",
       "3                    39.735099  19.876457  \n",
       "4                    41.643583  22.357433  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path) \n",
    "df['FOG INDEX'] = None  # Create a new column\n",
    "\n",
    "def calculate_fog_index(avg_sentence_length, percentage_complex_words):\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    return fog_index\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            sentences = sent_tokenize(text)\n",
    "            num_sentences = len(sentences)\n",
    "            words = word_tokenize(text)\n",
    "            num_words = len(words)\n",
    "            if num_sentences > 0:\n",
    "                avg_sentence_length = num_words / num_sentences\n",
    "            else:\n",
    "                avg_sentence_length = 0\n",
    "            num_complex_words = sum(1 for word in words if len(word) > 6)\n",
    "            num_words = len(words)\n",
    "            if num_words > 0:\n",
    "                percentage_complex_words = (num_complex_words / num_words) * 100\n",
    "            else:\n",
    "                percentage_complex_words = 0\n",
    "            fog_index = calculate_fog_index(avg_sentence_length, percentage_complex_words)\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'FOG INDEX'] = fog_index\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f8a92",
   "metadata": {},
   "source": [
    "# Calculating the AVG NUMBER OF WORDS PER SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d631cb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>52.660842</td>\n",
       "      <td>27.779003</td>\n",
       "      <td>16.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>35.810811</td>\n",
       "      <td>18.878170</td>\n",
       "      <td>11.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>52.225250</td>\n",
       "      <td>26.132957</td>\n",
       "      <td>13.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>39.735099</td>\n",
       "      <td>19.876457</td>\n",
       "      <td>9.956044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>41.643583</td>\n",
       "      <td>22.357433</td>\n",
       "      <td>14.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              26        0.358025            0.077885            16.786667   \n",
       "1              28        0.232877            0.110774            11.384615   \n",
       "2              29        0.325581            0.097175            13.107143   \n",
       "3              14        0.471698            0.072503             9.956044   \n",
       "4              18        0.400000            0.070671            14.250000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX AVG NUMBER OF WORDS PER SENTENCE  \n",
       "0                    52.660842  27.779003                        16.786667  \n",
       "1                    35.810811  18.878170                        11.384615  \n",
       "2                    52.225250  26.132957                        13.107143  \n",
       "3                    39.735099  19.876457                         9.956044  \n",
       "4                    41.643583  22.357433                            14.25  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)  \n",
    "df['AVG NUMBER OF WORDS PER SENTENCE'] = None  # Create a new column\n",
    "\n",
    "def calculate_avg_words_per_sentence(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    words = word_tokenize(text)\n",
    "    num_words = len(words)\n",
    "    if num_sentences > 0:\n",
    "        avg_words_per_sentence = num_words / num_sentences\n",
    "    else:\n",
    "        avg_words_per_sentence = 0\n",
    "    return avg_words_per_sentence\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            avg_words_per_sentence = calculate_avg_words_per_sentence(text)\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'AVG NUMBER OF WORDS PER SENTENCE'] = avg_words_per_sentence\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb5288",
   "metadata": {},
   "source": [
    "# Calculating the COMPLEX WORD COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc74ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>52.660842</td>\n",
       "      <td>27.779003</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>35.810811</td>\n",
       "      <td>18.878170</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>52.225250</td>\n",
       "      <td>26.132957</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>39.735099</td>\n",
       "      <td>19.876457</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>41.643583</td>\n",
       "      <td>22.357433</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              26        0.358025            0.077885            16.786667   \n",
       "1              28        0.232877            0.110774            11.384615   \n",
       "2              29        0.325581            0.097175            13.107143   \n",
       "3              14        0.471698            0.072503             9.956044   \n",
       "4              18        0.400000            0.070671            14.250000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                    52.660842  27.779003                         16.786667   \n",
       "1                    35.810811  18.878170                         11.384615   \n",
       "2                    52.225250  26.132957                         13.107143   \n",
       "3                    39.735099  19.876457                          9.956044   \n",
       "4                    41.643583  22.357433                         14.250000   \n",
       "\n",
       "  COMPLEX WORD COUNT  \n",
       "0                663  \n",
       "1                318  \n",
       "2                575  \n",
       "3                360  \n",
       "4                451  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path) \n",
    "df['COMPLEX WORD COUNT'] = None  # Create a new column\n",
    "\n",
    "def calculate_complex_word_count(text):\n",
    "    words = word_tokenize(text)\n",
    "    complex_word_count = sum(1 for word in words if len(word) > 6)\n",
    "    return complex_word_count\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            complex_word_count = calculate_complex_word_count(text)\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'COMPLEX WORD COUNT'] = complex_word_count\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17265859",
   "metadata": {},
   "source": [
    "# Calculating the WORD COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64494cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>52.660842</td>\n",
       "      <td>27.779003</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>663</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>35.810811</td>\n",
       "      <td>18.878170</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>318</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>52.225250</td>\n",
       "      <td>26.132957</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>575</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>39.735099</td>\n",
       "      <td>19.876457</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>360</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>41.643583</td>\n",
       "      <td>22.357433</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>451</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              26        0.358025            0.077885            16.786667   \n",
       "1              28        0.232877            0.110774            11.384615   \n",
       "2              29        0.325581            0.097175            13.107143   \n",
       "3              14        0.471698            0.072503             9.956044   \n",
       "4              18        0.400000            0.070671            14.250000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                    52.660842  27.779003                         16.786667   \n",
       "1                    35.810811  18.878170                         11.384615   \n",
       "2                    52.225250  26.132957                         13.107143   \n",
       "3                    39.735099  19.876457                          9.956044   \n",
       "4                    41.643583  22.357433                         14.250000   \n",
       "\n",
       "   COMPLEX WORD COUNT WORD COUNT  \n",
       "0                 663       1065  \n",
       "1                 318        698  \n",
       "2                 575        907  \n",
       "3                 360        743  \n",
       "4                 451        900  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)  \n",
    "df['WORD COUNT'] = None  # Create a new column\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    return ''.join(ch for ch in word if ch not in punctuation)\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            words = word_tokenize(text)\n",
    "            words = [remove_punctuation(word) for word in words]\n",
    "            words = [word for word in words if word]  # Remove empty strings\n",
    "            word_count = len(words)\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'WORD COUNT'] = word_count\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda777ec",
   "metadata": {},
   "source": [
    "# Calculating the SYLLABLE PER WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26424e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>52.660842</td>\n",
       "      <td>27.779003</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>663</td>\n",
       "      <td>1065</td>\n",
       "      <td>2454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>35.810811</td>\n",
       "      <td>18.878170</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>318</td>\n",
       "      <td>698</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>52.225250</td>\n",
       "      <td>26.132957</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>575</td>\n",
       "      <td>907</td>\n",
       "      <td>2148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>39.735099</td>\n",
       "      <td>19.876457</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>360</td>\n",
       "      <td>743</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>41.643583</td>\n",
       "      <td>22.357433</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>451</td>\n",
       "      <td>900</td>\n",
       "      <td>1871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              26        0.358025            0.077885            16.786667   \n",
       "1              28        0.232877            0.110774            11.384615   \n",
       "2              29        0.325581            0.097175            13.107143   \n",
       "3              14        0.471698            0.072503             9.956044   \n",
       "4              18        0.400000            0.070671            14.250000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                    52.660842  27.779003                         16.786667   \n",
       "1                    35.810811  18.878170                         11.384615   \n",
       "2                    52.225250  26.132957                         13.107143   \n",
       "3                    39.735099  19.876457                          9.956044   \n",
       "4                    41.643583  22.357433                         14.250000   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT SYLLABLE PER WORD  \n",
       "0                 663        1065              2454  \n",
       "1                 318         698              1373  \n",
       "2                 575         907              2148  \n",
       "3                 360         743              1569  \n",
       "4                 451         900              1871  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "df['SYLLABLE PER WORD'] = None  # Create a new column\n",
    "\n",
    "def count_syllables(word):\n",
    "    vowels = \"aeiou\"\n",
    "    exceptions = [\"es\", \"ed\"]\n",
    "    syllable_count = 0\n",
    "    prev_char = None\n",
    "    for char in word:\n",
    "        if char.lower() in vowels:\n",
    "            if prev_char is None or prev_char.lower() not in vowels:\n",
    "                syllable_count += 1\n",
    "        prev_char = char\n",
    "    for exception in exceptions:\n",
    "        if word.endswith(exception):\n",
    "            syllable_count -= 1\n",
    "            break\n",
    "    return syllable_count\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            words = word_tokenize(text)\n",
    "            syllable_per_word = sum(count_syllables(word) for word in words)\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'SYLLABLE PER WORD'] = syllable_per_word\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a96f7",
   "metadata": {},
   "source": [
    "# Calculating the PERSONAL PRONOUNS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc51ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>52.660842</td>\n",
       "      <td>27.779003</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>663</td>\n",
       "      <td>1065</td>\n",
       "      <td>2454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>35.810811</td>\n",
       "      <td>18.878170</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>318</td>\n",
       "      <td>698</td>\n",
       "      <td>1373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>52.225250</td>\n",
       "      <td>26.132957</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>575</td>\n",
       "      <td>907</td>\n",
       "      <td>2148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>39.735099</td>\n",
       "      <td>19.876457</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>360</td>\n",
       "      <td>743</td>\n",
       "      <td>1569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>41.643583</td>\n",
       "      <td>22.357433</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>451</td>\n",
       "      <td>900</td>\n",
       "      <td>1871</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              26        0.358025            0.077885            16.786667   \n",
       "1              28        0.232877            0.110774            11.384615   \n",
       "2              29        0.325581            0.097175            13.107143   \n",
       "3              14        0.471698            0.072503             9.956044   \n",
       "4              18        0.400000            0.070671            14.250000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                    52.660842  27.779003                         16.786667   \n",
       "1                    35.810811  18.878170                         11.384615   \n",
       "2                    52.225250  26.132957                         13.107143   \n",
       "3                    39.735099  19.876457                          9.956044   \n",
       "4                    41.643583  22.357433                         14.250000   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD PERSONAL PRONOUNS  \n",
       "0                 663        1065               2454                 1  \n",
       "1                 318         698               1373                 1  \n",
       "2                 575         907               2148                 1  \n",
       "3                 360         743               1569                 0  \n",
       "4                 451         900               1871                 3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path)\n",
    "df['PERSONAL PRONOUNS'] = None  # Create a new column\n",
    "\n",
    "personal_pronoun_pattern = r'\\b(?<!US)(I|we|my|ours|us)\\b'\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            count_personal_pronouns = len(re.findall(personal_pronoun_pattern, text, flags=re.IGNORECASE))\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'PERSONAL PRONOUNS'] = count_personal_pronouns\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb8380",
   "metadata": {},
   "source": [
    "# Calculating the AVG WORD LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73665a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>52.660842</td>\n",
       "      <td>27.779003</td>\n",
       "      <td>16.786667</td>\n",
       "      <td>663</td>\n",
       "      <td>1065</td>\n",
       "      <td>2454</td>\n",
       "      <td>1</td>\n",
       "      <td>7.654808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>35.810811</td>\n",
       "      <td>18.878170</td>\n",
       "      <td>11.384615</td>\n",
       "      <td>318</td>\n",
       "      <td>698</td>\n",
       "      <td>1373</td>\n",
       "      <td>1</td>\n",
       "      <td>6.992413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>52.225250</td>\n",
       "      <td>26.132957</td>\n",
       "      <td>13.107143</td>\n",
       "      <td>575</td>\n",
       "      <td>907</td>\n",
       "      <td>2148</td>\n",
       "      <td>1</td>\n",
       "      <td>7.712994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.072503</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>39.735099</td>\n",
       "      <td>19.876457</td>\n",
       "      <td>9.956044</td>\n",
       "      <td>360</td>\n",
       "      <td>743</td>\n",
       "      <td>1569</td>\n",
       "      <td>0</td>\n",
       "      <td>6.846785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>41.643583</td>\n",
       "      <td>22.357433</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>451</td>\n",
       "      <td>900</td>\n",
       "      <td>1871</td>\n",
       "      <td>3</td>\n",
       "      <td>7.254417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...              55   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...              45   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...              57   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              39   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              42   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              26        0.358025            0.077885            16.786667   \n",
       "1              28        0.232877            0.110774            11.384615   \n",
       "2              29        0.325581            0.097175            13.107143   \n",
       "3              14        0.471698            0.072503             9.956044   \n",
       "4              18        0.400000            0.070671            14.250000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                    52.660842  27.779003                         16.786667   \n",
       "1                    35.810811  18.878170                         11.384615   \n",
       "2                    52.225250  26.132957                         13.107143   \n",
       "3                    39.735099  19.876457                          9.956044   \n",
       "4                    41.643583  22.357433                         14.250000   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 663        1065               2454                  1   \n",
       "1                 318         698               1373                  1   \n",
       "2                 575         907               2148                  1   \n",
       "3                 360         743               1569                  0   \n",
       "4                 451         900               1871                  3   \n",
       "\n",
       "  AVG WORD LENGTH  \n",
       "0        7.654808  \n",
       "1        6.992413  \n",
       "2        7.712994  \n",
       "3        6.846785  \n",
       "4        7.254417  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Extracted_TextFiles_Stopword_removed\"\n",
    "dataset_path = r\"C:\\Users\\hp\\Machine Learning\\Internship_Online\\Output Data Structure.xlsx\"\n",
    "\n",
    "df = pd.read_excel(dataset_path) \n",
    "df['AVG WORD LENGTH'] = None  # Create a new column\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            words = text.split()\n",
    "            total_characters = sum(len(word) for word in words)\n",
    "            num_words = len(words)\n",
    "            if num_words > 0:\n",
    "                avg_word_length = total_characters / num_words\n",
    "            else:\n",
    "                avg_word_length = 0\n",
    "            df.loc[df['URL_ID'] == float(file_name[:-4]), 'AVG WORD LENGTH'] = avg_word_length\n",
    "\n",
    "df.to_excel(dataset_path, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdaaff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
